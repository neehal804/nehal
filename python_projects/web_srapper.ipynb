{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cfe0147",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'request'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e392607f0c42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'request'"
     ]
    }
   ],
   "source": [
    "import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ab34842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped page 1\n",
      "scraped page 2\n",
      "scraped page 3\n",
      "scraped page 4\n",
      "scraped page 5\n",
      "scraped page 6\n",
      "scraped page 7\n",
      "scraped page 8\n",
      "scraped page 9\n",
      "scraped page 10\n",
      "inserted 100 articles\n"
     ]
    }
   ],
   "source": [
    "#web scrapper using python and mongodb\n",
    "\n",
    "#nehal bhosale & aashishkiran singh\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pymongo\n",
    "def scrape_quotes():\n",
    "    more_links = True\n",
    "    page = 1\n",
    "    quotes = []\n",
    "    while(more_links):\n",
    "        markup = requests.get(f'http://quotes.toscrape.com/page/{page}').text\n",
    "        soup = BeautifulSoup(markup, 'html.parser')\n",
    "        for item in soup.select('.quote'):\n",
    "            quote = {}\n",
    "            quote['text'] = item.select_one('.text').get_text()\n",
    "            quote['author'] = item.select_one('.author').get_text()\n",
    "            tags = item.select_one('.tags')\n",
    "            quote['tags'] = [tag.get_text() for tag in tags.select('.tag')]\n",
    "            quotes.append(quote)\n",
    "        next_link = soup.select_one('.next > a')\n",
    "        print(f'scraped page {page}')\n",
    "        if(next_link):\n",
    "            page += 1\n",
    "        else:\n",
    "            more_links = False\n",
    "    return quotes\n",
    "quotes = scrape_quotes()\n",
    "client = pymongo.MongoClient('mongodb://localhost:27017/?readPreference=primary&appname=MongoDB%20Compass&ssl=false')\n",
    "db = client.db.quotes\n",
    "try:\n",
    "    db.insert_many(quotes)\n",
    "    print(f'inserted {len(quotes)} articles')\n",
    "except:\n",
    "    print('an error occurred quotes were not stored to db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa3f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44448629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
